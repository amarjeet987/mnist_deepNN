{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot = True)\n",
    "tf.logging.set_verbosity(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, n_inputs, n_outputs, n_layers, n_neurons):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        #weights\n",
    "        curr_weight = tf.Variable(tf.random_normal([n_inputs if i == 0 else n_neurons[i-1], n_neurons[i]]), \n",
    "                                  name = \"w_\" + str(i))\n",
    "        weights.append(curr_weight)\n",
    "        \n",
    "        #bias\n",
    "        curr_bias = tf.Variable(tf.random_normal([n_neurons[i]]), name = \"b_\" + str(i))\n",
    "        biases.append(curr_bias)\n",
    "        \n",
    "    # For the last layer\n",
    "    \n",
    "    #weight\n",
    "    curr_weight = tf.Variable(tf.random_normal([n_neurons[n_layers - 1] if n_layers > 0 else n_inputs, n_outputs]),\n",
    "                             name = \"w_out\")\n",
    "    weights.append(curr_weight)\n",
    "    \n",
    "    #bias\n",
    "    curr_bias = tf.Variable(tf.random_normal([n_outputs]), name = \"b_out\")\n",
    "    biases.append(curr_bias)\n",
    "    \n",
    "    # start\n",
    "    layer = x\n",
    "    \n",
    "    # for the hidden layers\n",
    "    for i in range(n_layers):\n",
    "        layer = tf.nn.relu(tf.matmul(layer, weights[i]) + biases[i])\n",
    "        print(layer.shape, weights[i].shape, biases[i].shape)\n",
    "        \n",
    "    # for the output layer\n",
    "    print(layer.shape, weights[n_layers].shape, biases[n_layers].shape)\n",
    "    layer = tf.matmul(layer, weights[n_layers]) + biases[n_layers]\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batches(batch_size = 100):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(batch_size)  # sending the training data through here\n",
    "    return [X_batch, Y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_classification(batch_function, batch_size, n_batches,\n",
    "                              n_epochs, model, loss, optimizer, accuracy_function,\n",
    "                              x_test, y_test):\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in range(n_batches):\n",
    "                X_batch, Y_batch = batch_function(batch_size)\n",
    "                a, batch_loss = sess.run([optimizer, loss], feed_dict = { x : X_batch, y : Y_batch })\n",
    "                epoch_loss += batch_loss\n",
    "            avg_loss = epoch_loss / n_batches\n",
    "            print(\"For epoch : \" + str(epoch))\n",
    "            print(\"a :\" + str(a))\n",
    "            print(\"loss : \" + str(avg_loss))\n",
    "        \n",
    "        # Now for our testset\n",
    "        \n",
    "        accuracy_score = sess.run(accuracy_function, feed_dict = { x : x_test, y : y_test })\n",
    "        print(\"Accuracy : \" + str(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_layers = 2\n",
    "n_neurons = []\n",
    "\n",
    "for i in range(n_layers):\n",
    "    n_neurons.append(256)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "n_batches = mnist.train.num_examples / batch_size\n",
    "\n",
    "n_inputs = 784\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 256) (784, 256) (256,)\n",
      "(?, 256) (256, 256) (256,)\n",
      "(?, 256) (256, 10) (10,)\n",
      "Level 1:tensorflow:Gradient for 'Mean'\n",
      "Level 1:tensorflow:  in  --> gradients/Fill:0\n",
      "Level 1:tensorflow:  out --> gradients/Mean_grad/truediv:0\n",
      "Level 1:tensorflow:Gradient for 'softmax_cross_entropy_with_logits/Reshape_2'\n",
      "Level 1:tensorflow:  in  --> gradients/Mean_grad/truediv:0\n",
      "Level 1:tensorflow:  out --> gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape:0\n",
      "Level 1:tensorflow:Gradient for 'softmax_cross_entropy_with_logits'\n",
      "Level 1:tensorflow:  in  --> gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape:0, gradients/zeros_like:0\n",
      "Level 1:tensorflow:  out --> gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency:0, gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'softmax_cross_entropy_with_logits/Reshape'\n",
      "Level 1:tensorflow:  in  --> gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape:0\n",
      "Level 1:tensorflow:Gradient for 'add_2'\n",
      "Level 1:tensorflow:  in  --> gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape:0\n",
      "Level 1:tensorflow:  out --> gradients/add_2_grad/tuple/control_dependency:0, gradients/add_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'MatMul_2'\n",
      "Level 1:tensorflow:  in  --> gradients/add_2_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_2_grad/tuple/control_dependency:0, gradients/MatMul_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'b_out/read'\n",
      "Level 1:tensorflow:  in  --> gradients/add_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/add_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'Relu_1'\n",
      "Level 1:tensorflow:  in  --> gradients/MatMul_2_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/Relu_1_grad/ReluGrad:0\n",
      "Level 1:tensorflow:Gradient for 'w_out/read'\n",
      "Level 1:tensorflow:  in  --> gradients/MatMul_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_2_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'add_1'\n",
      "Level 1:tensorflow:  in  --> gradients/Relu_1_grad/ReluGrad:0\n",
      "Level 1:tensorflow:  out --> gradients/add_1_grad/tuple/control_dependency:0, gradients/add_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'MatMul_1'\n",
      "Level 1:tensorflow:  in  --> gradients/add_1_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_1_grad/tuple/control_dependency:0, gradients/MatMul_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'b_1/read'\n",
      "Level 1:tensorflow:  in  --> gradients/add_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/add_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'Relu'\n",
      "Level 1:tensorflow:  in  --> gradients/MatMul_1_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/Relu_grad/ReluGrad:0\n",
      "Level 1:tensorflow:Gradient for 'w_1/read'\n",
      "Level 1:tensorflow:  in  --> gradients/MatMul_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_1_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'add'\n",
      "Level 1:tensorflow:  in  --> gradients/Relu_grad/ReluGrad:0\n",
      "Level 1:tensorflow:  out --> gradients/add_grad/tuple/control_dependency:0, gradients/add_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'MatMul'\n",
      "Level 1:tensorflow:  in  --> gradients/add_grad/tuple/control_dependency:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_grad/tuple/control_dependency:0, gradients/MatMul_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'b_0/read'\n",
      "Level 1:tensorflow:  in  --> gradients/add_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/add_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Gradient for 'w_0/read'\n",
      "Level 1:tensorflow:  in  --> gradients/MatMul_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:  out --> gradients/MatMul_grad/tuple/control_dependency_1:0\n",
      "Level 1:tensorflow:Created variable w_0/Adam:0 with shape (784, 256) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F28041DFD0>\n",
      "Level 1:tensorflow:Created variable w_0/Adam_1:0 with shape (784, 256) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F28041DE10>\n",
      "Level 1:tensorflow:Created variable b_0/Adam:0 with shape (256,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F28041DE80>\n",
      "Level 1:tensorflow:Created variable b_0/Adam_1:0 with shape (256,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F28041DEB8>\n",
      "Level 1:tensorflow:Created variable w_1/Adam:0 with shape (256, 256) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F28041DE48>\n",
      "Level 1:tensorflow:Created variable w_1/Adam_1:0 with shape (256, 256) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F280436208>\n",
      "Level 1:tensorflow:Created variable b_1/Adam:0 with shape (256,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F2804361D0>\n",
      "Level 1:tensorflow:Created variable b_1/Adam_1:0 with shape (256,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F280436518>\n",
      "Level 1:tensorflow:Created variable w_out/Adam:0 with shape (256, 10) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F280436278>\n",
      "Level 1:tensorflow:Created variable w_out/Adam_1:0 with shape (256, 10) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F2804362B0>\n",
      "Level 1:tensorflow:Created variable b_out/Adam:0 with shape (10,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F2804366D8>\n",
      "Level 1:tensorflow:Created variable b_out/Adam_1:0 with shape (10,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x000001F280436438>\n",
      "For epoch : 0\n",
      "a :None\n",
      "loss : 39.14550972916863\n",
      "For epoch : 1\n",
      "a :None\n",
      "loss : 7.262061086595058\n",
      "For epoch : 2\n",
      "a :None\n",
      "loss : 4.160977638328571\n",
      "For epoch : 3\n",
      "a :None\n",
      "loss : 2.776338865506037\n",
      "For epoch : 4\n",
      "a :None\n",
      "loss : 2.287429972734032\n",
      "Accuracy : 0.9537\n"
     ]
    }
   ],
   "source": [
    "# input images\n",
    "\n",
    "x = tf.placeholder(dtype=\"float32\", shape = [None, n_inputs], name = \"x\")\n",
    "y = tf.placeholder(dtype=\"float32\", shape = [None, n_outputs], name = \"y\")\n",
    "\n",
    "# set the model\n",
    "\n",
    "model = mlp(x, n_inputs, n_outputs, n_layers, n_neurons)\n",
    "\n",
    "# calculate the loss\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels = y))\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(mnist_batches, batch_size, int(n_batches),\n",
    "                              n_epochs, model, loss, optimizer,\n",
    "                              accuracy_function, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
